export type EchoModelName = keyof typeof ECHO_MODELS;

export type EchoModelState = Record<string, EchoModel>;

export interface EchoModel {
  max_tokens: number;
  max_input_tokens: number;
  max_output_tokens: number;
  input_cost_per_token: number;
  output_cost_per_token: number;
}

export const ECHO_MODELS = {
  "gpt-4": {
    max_tokens: 4096,
    max_input_tokens: 8192,
    max_output_tokens: 4096,
    input_cost_per_token: 3e-5,
    output_cost_per_token: 6e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4.1": {
    max_tokens: 32768,
    max_input_tokens: 1047576,
    max_output_tokens: 32768,
    input_cost_per_token: 2e-6,
    output_cost_per_token: 8e-6,
    input_cost_per_token_batches: 1e-6,
    output_cost_per_token_batches: 4e-6,
    cache_read_input_token_cost: 5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_native_streaming: true,
  },
  "gpt-4.1-2025-04-14": {
    max_tokens: 32768,
    max_input_tokens: 1047576,
    max_output_tokens: 32768,
    input_cost_per_token: 2e-6,
    output_cost_per_token: 8e-6,
    input_cost_per_token_batches: 1e-6,
    output_cost_per_token_batches: 4e-6,
    cache_read_input_token_cost: 5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_native_streaming: true,
  },
  "gpt-4.1-mini": {
    max_tokens: 32768,
    max_input_tokens: 1047576,
    max_output_tokens: 32768,
    input_cost_per_token: 4e-7,
    output_cost_per_token: 1.6e-6,
    input_cost_per_token_batches: 2e-7,
    output_cost_per_token_batches: 8e-7,
    cache_read_input_token_cost: 1e-7,
    litellm_provider: "openai",
    mode: "chat",
    supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_native_streaming: true,
  },
  "gpt-4.1-mini-2025-04-14": {
    max_tokens: 32768,
    max_input_tokens: 1047576,
    max_output_tokens: 32768,
    input_cost_per_token: 4e-7,
    output_cost_per_token: 1.6e-6,
    input_cost_per_token_batches: 2e-7,
    output_cost_per_token_batches: 8e-7,
    cache_read_input_token_cost: 1e-7,
    litellm_provider: "openai",
    mode: "chat",
    supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_native_streaming: true,
  },
  "gpt-4.1-nano": {
    max_tokens: 32768,
    max_input_tokens: 1047576,
    max_output_tokens: 32768,
    input_cost_per_token: 1e-7,
    output_cost_per_token: 4e-7,
    input_cost_per_token_batches: 5e-8,
    output_cost_per_token_batches: 2e-7,
    cache_read_input_token_cost: 2.5e-8,
    litellm_provider: "openai",
    mode: "chat",
    supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_native_streaming: true,
  },
  "gpt-4.1-nano-2025-04-14": {
    max_tokens: 32768,
    max_input_tokens: 1047576,
    max_output_tokens: 32768,
    input_cost_per_token: 1e-7,
    output_cost_per_token: 4e-7,
    input_cost_per_token_batches: 5e-8,
    output_cost_per_token_batches: 2e-7,
    cache_read_input_token_cost: 2.5e-8,
    litellm_provider: "openai",
    mode: "chat",
    supported_endpoints: ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_native_streaming: true,
  },
  "gpt-4o": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    output_cost_per_token: 1e-5,
    input_cost_per_token_batches: 1.25e-6,
    output_cost_per_token_batches: 5e-6,
    cache_read_input_token_cost: 1.25e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-search-preview-2025-03-11": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    output_cost_per_token: 1e-5,
    input_cost_per_token_batches: 1.25e-6,
    output_cost_per_token_batches: 5e-6,
    cache_read_input_token_cost: 1.25e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-search-preview": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    output_cost_per_token: 1e-5,
    input_cost_per_token_batches: 1.25e-6,
    output_cost_per_token_batches: 5e-6,
    cache_read_input_token_cost: 1.25e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_web_search: true,
    search_context_cost_per_query: {
      search_context_size_low: 0.03,
      search_context_size_medium: 0.035,
      search_context_size_high: 0.05,
    },
  },
  "gpt-4.5-preview": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 7.5e-5,
    output_cost_per_token: 0.00015,
    input_cost_per_token_batches: 3.75e-5,
    output_cost_per_token_batches: 7.5e-5,
    cache_read_input_token_cost: 3.75e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4.5-preview-2025-02-27": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 7.5e-5,
    output_cost_per_token: 0.00015,
    input_cost_per_token_batches: 3.75e-5,
    output_cost_per_token_batches: 7.5e-5,
    cache_read_input_token_cost: 3.75e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    deprecation_date: "2025-07-14",
  },
  "gpt-4o-audio-preview": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    input_cost_per_audio_token: 0.0001,
    output_cost_per_token: 1e-5,
    output_cost_per_audio_token: 0.0002,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-audio-preview-2024-12-17": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    input_cost_per_audio_token: 4e-5,
    output_cost_per_token: 1e-5,
    output_cost_per_audio_token: 8e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-audio-preview-2024-10-01": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    input_cost_per_audio_token: 0.0001,
    output_cost_per_token: 1e-5,
    output_cost_per_audio_token: 0.0002,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-audio-preview-2025-06-03": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    input_cost_per_audio_token: 4e-5,
    output_cost_per_token: 1e-5,
    output_cost_per_audio_token: 8e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini-audio-preview": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 1.5e-7,
    input_cost_per_audio_token: 1e-5,
    output_cost_per_token: 6e-7,
    output_cost_per_audio_token: 2e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini-audio-preview-2024-12-17": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 1.5e-7,
    input_cost_per_audio_token: 1e-5,
    output_cost_per_token: 6e-7,
    output_cost_per_audio_token: 2e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 1.5e-7,
    output_cost_per_token: 6e-7,
    input_cost_per_token_batches: 7.5e-8,
    output_cost_per_token_batches: 3e-7,
    cache_read_input_token_cost: 7.5e-8,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini-search-preview-2025-03-11": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 1.5e-7,
    output_cost_per_token: 6e-7,
    input_cost_per_token_batches: 7.5e-8,
    output_cost_per_token_batches: 3e-7,
    cache_read_input_token_cost: 7.5e-8,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini-search-preview": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 1.5e-7,
    output_cost_per_token: 6e-7,
    input_cost_per_token_batches: 7.5e-8,
    output_cost_per_token_batches: 3e-7,
    cache_read_input_token_cost: 7.5e-8,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    supports_web_search: true,
    search_context_cost_per_query: {
      search_context_size_low: 0.025,
      search_context_size_medium: 0.0275,
      search_context_size_high: 0.03,
    },
  },
  "gpt-4o-mini-2024-07-18": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 1.5e-7,
    output_cost_per_token: 6e-7,
    input_cost_per_token_batches: 7.5e-8,
    output_cost_per_token_batches: 3e-7,
    cache_read_input_token_cost: 7.5e-8,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
    search_context_cost_per_query: {
      search_context_size_low: 30.0,
      search_context_size_medium: 35.0,
      search_context_size_high: 50.0,
    },
  },
  o1: {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 1.5e-5,
    output_cost_per_token: 6e-5,
    cache_read_input_token_cost: 7.5e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_vision: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
  },
  "o1-mini": {
    max_tokens: 65536,
    max_input_tokens: 128000,
    max_output_tokens: 65536,
    input_cost_per_token: 1.1e-6,
    output_cost_per_token: 4.4e-6,
    cache_read_input_token_cost: 5.5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_vision: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
  },
  o3: {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 2e-6,
    output_cost_per_token: 8e-6,
    cache_read_input_token_cost: 5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: false,
    supports_vision: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
    supported_endpoints: [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch",
    ],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
  },
  "o3-2025-04-16": {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 2e-6,
    output_cost_per_token: 8e-6,
    cache_read_input_token_cost: 5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: false,
    supports_vision: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
    supported_endpoints: [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch",
    ],
    supported_modalities: ["text", "image"],
    supported_output_modalities: ["text"],
  },
  "o3-mini": {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 1.1e-6,
    output_cost_per_token: 4.4e-6,
    cache_read_input_token_cost: 5.5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: false,
    supports_vision: false,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
  },
  "o3-mini-2025-01-31": {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 1.1e-6,
    output_cost_per_token: 4.4e-6,
    cache_read_input_token_cost: 5.5e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: false,
    supports_vision: false,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
  },
  "o4-mini": {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 1.1e-6,
    output_cost_per_token: 4.4e-6,
    cache_read_input_token_cost: 2.75e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: false,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
  },
  "o4-mini-2025-04-16": {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 1.1e-6,
    output_cost_per_token: 4.4e-6,
    cache_read_input_token_cost: 2.75e-7,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: false,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
  },
  "o1-mini-2024-09-12": {
    max_tokens: 65536,
    max_input_tokens: 128000,
    max_output_tokens: 65536,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.2e-5,
    cache_read_input_token_cost: 1.5e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_vision: true,
    supports_reasoning: true,
    supports_prompt_caching: true,
  },
  "o1-preview": {
    max_tokens: 32768,
    max_input_tokens: 128000,
    max_output_tokens: 32768,
    input_cost_per_token: 1.5e-5,
    output_cost_per_token: 6e-5,
    cache_read_input_token_cost: 7.5e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_vision: true,
    supports_reasoning: true,
    supports_prompt_caching: true,
  },
  "o1-preview-2024-09-12": {
    max_tokens: 32768,
    max_input_tokens: 128000,
    max_output_tokens: 32768,
    input_cost_per_token: 1.5e-5,
    output_cost_per_token: 6e-5,
    cache_read_input_token_cost: 7.5e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_vision: true,
    supports_reasoning: true,
    supports_prompt_caching: true,
  },
  "o1-2024-12-17": {
    max_tokens: 100000,
    max_input_tokens: 200000,
    max_output_tokens: 100000,
    input_cost_per_token: 1.5e-5,
    output_cost_per_token: 6e-5,
    cache_read_input_token_cost: 7.5e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_response_schema: true,
    supports_reasoning: true,
    supports_tool_choice: true,
  },
  "chatgpt-4o-latest": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 5e-6,
    output_cost_per_token: 1.5e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-2024-05-13": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 5e-6,
    output_cost_per_token: 1.5e-5,
    input_cost_per_token_batches: 2.5e-6,
    output_cost_per_token_batches: 7.5e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-2024-08-06": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    output_cost_per_token: 1e-5,
    input_cost_per_token_batches: 1.25e-6,
    output_cost_per_token_batches: 5e-6,
    cache_read_input_token_cost: 1.25e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-2024-11-20": {
    max_tokens: 16384,
    max_input_tokens: 128000,
    max_output_tokens: 16384,
    input_cost_per_token: 2.5e-6,
    output_cost_per_token: 1e-5,
    input_cost_per_token_batches: 1.25e-6,
    output_cost_per_token_batches: 5e-6,
    cache_read_input_token_cost: 1.25e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_response_schema: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 5e-6,
    input_cost_per_audio_token: 0.0001,
    cache_read_input_token_cost: 2.5e-6,
    cache_creation_input_audio_token_cost: 2e-5,
    output_cost_per_token: 2e-5,
    output_cost_per_audio_token: 0.0002,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-realtime-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 5e-6,
    input_cost_per_audio_token: 4e-5,
    cache_read_input_token_cost: 2.5e-6,
    output_cost_per_token: 2e-5,
    output_cost_per_audio_token: 8e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 5e-6,
    input_cost_per_audio_token: 4e-5,
    cache_read_input_token_cost: 2.5e-6,
    output_cost_per_token: 2e-5,
    output_cost_per_audio_token: 8e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini-realtime-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 6e-7,
    input_cost_per_audio_token: 1e-5,
    cache_read_input_token_cost: 3e-7,
    cache_creation_input_audio_token_cost: 3e-7,
    output_cost_per_token: 2.4e-6,
    output_cost_per_audio_token: 2e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4o-mini-realtime-preview-2024-12-17": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 6e-7,
    input_cost_per_audio_token: 1e-5,
    cache_read_input_token_cost: 3e-7,
    cache_creation_input_audio_token_cost: 3e-7,
    output_cost_per_token: 2.4e-6,
    output_cost_per_audio_token: 2e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_audio_input: true,
    supports_audio_output: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-turbo-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-0314": {
    max_tokens: 4096,
    max_input_tokens: 8192,
    max_output_tokens: 4096,
    input_cost_per_token: 3e-5,
    output_cost_per_token: 6e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-0613": {
    max_tokens: 4096,
    max_input_tokens: 8192,
    max_output_tokens: 4096,
    input_cost_per_token: 3e-5,
    output_cost_per_token: 6e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    deprecation_date: "2025-06-06",
    supports_tool_choice: true,
  },
  "gpt-4-32k": {
    max_tokens: 4096,
    max_input_tokens: 32768,
    max_output_tokens: 4096,
    input_cost_per_token: 6e-5,
    output_cost_per_token: 0.00012,
    litellm_provider: "openai",
    mode: "chat",
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-32k-0314": {
    max_tokens: 4096,
    max_input_tokens: 32768,
    max_output_tokens: 4096,
    input_cost_per_token: 6e-5,
    output_cost_per_token: 0.00012,
    litellm_provider: "openai",
    mode: "chat",
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-32k-0613": {
    max_tokens: 4096,
    max_input_tokens: 32768,
    max_output_tokens: 4096,
    input_cost_per_token: 6e-5,
    output_cost_per_token: 0.00012,
    litellm_provider: "openai",
    mode: "chat",
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-turbo": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-turbo-2024-04-09": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_pdf_input: true,
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_vision: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-1106-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-0125-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_parallel_function_calling: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-4-vision-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_vision: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    deprecation_date: "2024-12-06",
    supports_tool_choice: true,
  },
  "gpt-4-1106-vision-preview": {
    max_tokens: 4096,
    max_input_tokens: 128000,
    max_output_tokens: 4096,
    input_cost_per_token: 1e-5,
    output_cost_per_token: 3e-5,
    litellm_provider: "openai",
    mode: "chat",
    supports_vision: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    deprecation_date: "2024-12-06",
    supports_tool_choice: true,
  },
  "gpt-3.5-turbo": {
    max_tokens: 4097,
    max_input_tokens: 16385,
    max_output_tokens: 4096,
    input_cost_per_token: 1.5e-6,
    output_cost_per_token: 2e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_function_calling: true,
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "gpt-3.5-turbo-16k": {
    max_tokens: 16385,
    max_input_tokens: 16385,
    max_output_tokens: 4096,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 4e-6,
    litellm_provider: "openai",
    mode: "chat",
    supports_prompt_caching: true,
    supports_system_messages: true,
    supports_tool_choice: true,
  },
  "claude-opus-4-20250514": {
    max_tokens: 32000,
    max_input_tokens: 200000,
    max_output_tokens: 32000,
    input_cost_per_token: 1.5e-5,
    output_cost_per_token: 7.5e-5,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    cache_creation_input_token_cost: 1.875e-5,
    cache_read_input_token_cost: 1.5e-6,
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_tool_choice: true,
    supports_reasoning: true,
    supports_computer_use: true,
  },
  "claude-sonnet-4-20250514": {
    max_tokens: 64000,
    max_input_tokens: 200000,
    max_output_tokens: 64000,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_tool_choice: true,
    supports_reasoning: true,
    supports_computer_use: true,
  },
  "claude-4-opus-20250514": {
    max_tokens: 32000,
    max_input_tokens: 200000,
    max_output_tokens: 32000,
    input_cost_per_token: 1.5e-5,
    output_cost_per_token: 7.5e-5,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    cache_creation_input_token_cost: 1.875e-5,
    cache_read_input_token_cost: 1.5e-6,
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_tool_choice: true,
    supports_reasoning: true,
    supports_computer_use: true,
  },
  "claude-4-sonnet-20250514": {
    max_tokens: 64000,
    max_input_tokens: 200000,
    max_output_tokens: 64000,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    supports_tool_choice: true,
    supports_reasoning: true,
    supports_computer_use: true,
  },
  "claude-3-7-sonnet-latest": {
    supports_computer_use: true,
    max_tokens: 128000,
    max_input_tokens: 200000,
    max_output_tokens: 128000,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    deprecation_date: "2025-06-01",
    supports_tool_choice: true,
    supports_reasoning: true,
  },
  "claude-3-7-sonnet-20250219": {
    supports_computer_use: true,
    max_tokens: 128000,
    max_input_tokens: 200000,
    max_output_tokens: 128000,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    deprecation_date: "2026-02-01",
    supports_tool_choice: true,
    supports_reasoning: true,
    supports_web_search: true,
  },
  "claude-3-5-sonnet-20241022": {
    supports_computer_use: true,
    max_tokens: 8192,
    max_input_tokens: 200000,
    max_output_tokens: 8192,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    deprecation_date: "2025-10-01",
    supports_tool_choice: true,
    supports_web_search: true,
  },
  "claude-3-5-sonnet-latest": {
    supports_computer_use: true,
    max_tokens: 8192,
    max_input_tokens: 200000,
    max_output_tokens: 8192,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    search_context_cost_per_query: {
      search_context_size_low: 0.01,
      search_context_size_medium: 0.01,
      search_context_size_high: 0.01,
    },
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    deprecation_date: "2025-06-01",
    supports_tool_choice: true,
    supports_web_search: true,
  },
  "claude-3-5-sonnet-20240620": {
    max_tokens: 8192,
    max_input_tokens: 200000,
    max_output_tokens: 8192,
    input_cost_per_token: 3e-6,
    output_cost_per_token: 1.5e-5,
    cache_creation_input_token_cost: 3.75e-6,
    cache_read_input_token_cost: 3e-7,
    litellm_provider: "anthropic",
    mode: "chat",
    supports_function_calling: true,
    supports_vision: true,
    tool_use_system_prompt_tokens: 159,
    supports_assistant_prefill: true,
    supports_pdf_input: true,
    supports_prompt_caching: true,
    supports_response_schema: true,
    deprecation_date: "2025-06-01",
    supports_tool_choice: true,
  },
  "gemini-2.5-flash": {
    max_tokens: 65535,
    max_input_tokens: 1048576,
    max_output_tokens: 65535,
    max_images_per_prompt: 3000,
    max_videos_per_prompt: 10,
    max_video_length: 1,
    max_audio_length_hours: 8.4,
    max_audio_per_prompt: 1,
    max_pdf_size_mb: 30,
    input_cost_per_audio_token: 1e-6,
    input_cost_per_token: 3e-7,
    output_cost_per_token: 2.5e-6,
    output_cost_per_reasoning_token: 2.5e-6,
    litellm_provider: "vertex_ai-language-models",
    mode: "chat",
    supports_reasoning: true,
    supports_system_messages: true,
    supports_function_calling: true,
    supports_vision: true,
    supports_response_schema: true,
    supports_audio_output: false,
    supports_tool_choice: true,
    supported_endpoints: [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch",
    ],
    supported_modalities: ["text", "image", "audio", "video"],
    supported_output_modalities: ["text"],
    source:
      "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    supports_parallel_function_calling: true,
    supports_web_search: true,
    supports_url_context: true,
    supports_pdf_input: true,
  },
  "gemini-2.5-pro": {
    max_tokens: 65535,
    max_input_tokens: 1048576,
    max_output_tokens: 65535,
    max_images_per_prompt: 3000,
    max_videos_per_prompt: 10,
    max_video_length: 1,
    max_audio_length_hours: 8.4,
    max_audio_per_prompt: 1,
    max_pdf_size_mb: 30,
    input_cost_per_token: 1.25e-6,
    input_cost_per_token_above_200k_tokens: 2.5e-6,
    output_cost_per_token: 1e-5,
    output_cost_per_token_above_200k_tokens: 1.5e-5,
    litellm_provider: "vertex_ai-language-models",
    mode: "chat",
    supports_system_messages: true,
    supports_function_calling: true,
    supports_vision: true,
    supports_audio_input: true,
    supports_video_input: true,
    supports_pdf_input: true,
    supports_response_schema: true,
    supports_tool_choice: true,
    supports_reasoning: true,
    supported_endpoints: ["/v1/chat/completions", "/v1/completions"],
    supported_modalities: ["text", "image", "audio", "video"],
    supported_output_modalities: ["text"],
    source: "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    supports_web_search: true,
  },
  "gemini-2.0-flash": {
    max_tokens: 8192,
    max_input_tokens: 1048576,
    max_output_tokens: 8192,
    max_images_per_prompt: 3000,
    max_videos_per_prompt: 10,
    max_video_length: 1,
    max_audio_length_hours: 8.4,
    max_audio_per_prompt: 1,
    max_pdf_size_mb: 30,
    input_cost_per_audio_token: 7e-7,
    input_cost_per_token: 1e-7,
    output_cost_per_token: 4e-7,
    litellm_provider: "vertex_ai-language-models",
    mode: "chat",
    supports_system_messages: true,
    supports_function_calling: true,
    supports_vision: true,
    supports_response_schema: true,
    supports_audio_output: true,
    supports_audio_input: true,
    supported_modalities: ["text", "image", "audio", "video"],
    supported_output_modalities: ["text", "image"],
    supports_tool_choice: true,
    source: "https://ai.google.dev/pricing#2_0flash",
    supports_parallel_function_calling: true,
    supports_web_search: true,
    supports_url_context: true,
  },
};
